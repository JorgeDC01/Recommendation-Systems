{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeDuHvop6Pl4"
      },
      "source": [
        "## 1. Non-Negative Matrix Factorization (NMF, scikit-learn package)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21eBwelH6Pl7"
      },
      "source": [
        "### 1 Load the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fCoCM7o76Pl-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# for interactive inline plots\n",
        "#%matplotlib notebook\n",
        "# for simple inline plots\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import time, math\n",
        "#from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "def ConvertToDense(X, y, shape):\n",
        "    row  = X[:, 0]\n",
        "    col  = X[:, 1]\n",
        "    data = y\n",
        "    matrix_sparse = sparse.csr_matrix((data, (row, col)), shape=(shape[0] + 1, shape[1] + 1))\n",
        "    R = matrix_sparse.todense()\n",
        "    R = R[1:, 1:]  # Remove offset\n",
        "    R = np.asarray(R)\n",
        "    return R\n",
        "\n",
        "\n",
        "def GetShape(filename):\n",
        "    names = ['user_id', 'item_id', 'rating']\n",
        "    df = pd.read_csv(filename)\n",
        "    df.rename(columns={'user':'user_id', 'item':'item_id', 'rating':'rating'}, inplace=True)\n",
        "    n_users = len(df['user_id'].unique())\n",
        "    n_items = len(df['item_id'].unique())\n",
        "    return (n_users, n_items)\n",
        "\n",
        "def LoadData(filename, R_shape):\n",
        "    df = pd.read_csv(filename)\n",
        "    df.rename(columns={'user': 'user_id', 'item': 'item_id', 'rating': 'rating'}, inplace=True)\n",
        "    # Encode user and item IDs to zero-based integer indices\n",
        "    user_encoder = LabelEncoder()\n",
        "    item_encoder = LabelEncoder()\n",
        "\n",
        "    df['user_id'] = user_encoder.fit_transform(df['user_id'])\n",
        "    df['item_id'] = item_encoder.fit_transform(df['item_id'])\n",
        "\n",
        "    X = df[['user_id', 'item_id']].values\n",
        "    y = df['rating'].values.astype(np.float64)  # Ensure y is numeric\n",
        "\n",
        "    return X, y, ConvertToDense(X, y, R_shape)\n",
        "\n",
        "\n",
        "R_shape = GetShape('train.csv')\n",
        "\n",
        "X, y, R = LoadData('train.csv', R_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Crd04-6Pl-"
      },
      "source": [
        "### 1.2 Split into training and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F2BMgP5V6Pl_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "R_train = ConvertToDense(X_train, y_train, R_shape)\n",
        "R_test = ConvertToDense(X_test, y_test, R_shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2GxDje56Pl_"
      },
      "source": [
        "### 1.3 Choose a model: NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4RuuGuZI6PmA"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "parametersNMF = {\n",
        "                    'n_components' : 20,     # number of latent factors\n",
        "                    'init' : 'random',\n",
        "                    'random_state' : 0,\n",
        "                    'l1_ratio' : 0,          # set regularization = L2\n",
        "                    'max_iter' : 15\n",
        "                }\n",
        "\n",
        "estimator = NMF(**parametersNMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgjYrYXP6PmA"
      },
      "source": [
        "##### Estimating the error (RMSE) before tuning the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZQ7guGmY6PmB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(pred, actual):\n",
        "    pred = pred[actual.nonzero()].flatten()     # Ignore nonzero terms\n",
        "    actual = actual[actual.nonzero()].flatten() # Ignore nonzero terms\n",
        "    return np.sqrt(mean_squared_error(pred, actual))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R_train = ConvertToDense(X_train, y_train, R_shape)\n",
        "R_test = ConvertToDense(X_test, y_test, R_shape)\n",
        "\n",
        "# Track time for training and evaluation\n",
        "start_time = time.time()\n",
        "\n",
        "# Convert the training data to sparse format\n",
        "R_train_sparse = sparse.csr_matrix((y_train, (X_train[:, 0], X_train[:, 1])), shape=R_shape)\n",
        "\n",
        "# Train NMF model on the training data\n",
        "estimator.fit(R_train_sparse)\n",
        "Theta = estimator.transform(R_train_sparse)  # User features\n",
        "M = estimator.components_.T  # Item features\n",
        "\n",
        "# Predict ratings for the training set\n",
        "R_pred_train = M.dot(Theta.T).T\n",
        "R_pred_train = np.clip(R_pred_train, 1, 5)  # Clip ratings between 1 and 5\n",
        "\n",
        "# Compute RMSE on the training data\n",
        "train_rmse = get_rmse(R_pred_train, R_train_sparse.toarray())\n",
        "\n",
        "# Predict ratings for the test set\n",
        "R_pred_test = M.dot(Theta.T).T\n",
        "R_pred_test = np.clip(R_pred_test, 1, 5)  # Clip ratings between 1 and 5\n",
        "\n",
        "# Compute RMSE on the test data\n",
        "R_test_sparse = sparse.csr_matrix((y_test, (X_test[:, 0], X_test[:, 1])), shape=R_shape)\n",
        "test_rmse = get_rmse(R_pred_test, R_test_sparse.toarray())\n",
        "\n",
        "# Print results\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Training Complete - Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}, Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymy1O2RUH5I_",
        "outputId": "e0f48c2b-bce1-4fd9-bdbb-e7efe6fdc8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_nmf.py:1742: ConvergenceWarning: Maximum number of iterations 15 reached. Increase it to improve convergence.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex_Atw076PmF"
      },
      "source": [
        "### 1.4 Final evaluation on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BO7ssUv7A_Yb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca616400-9f28-4133-83f0-1e32d8c0ca2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 23938/23938 [00:00<00:00, 115750.89pair/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Predictions saved to predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse\n",
        "\n",
        "# Load training data\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "# Encode user and item IDs\n",
        "df['user'] = user_encoder.fit_transform(df['user'])\n",
        "df['item'] = item_encoder.fit_transform(df['item'])\n",
        "\n",
        "# Define mappings for user and item IDs to apply to test data\n",
        "user_mapping = {u: i for i, u in enumerate(user_encoder.classes_)}\n",
        "item_mapping = {i: j for j, i in enumerate(item_encoder.classes_)}\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Encode user and item IDs using training mappings\n",
        "test_df['user'] = test_df['user'].map(user_mapping)  # Convert user IDs\n",
        "test_df['item'] = test_df['item'].map(item_mapping)  # Convert item IDs\n",
        "\n",
        "# Handle unknown users/items by dropping them\n",
        "test_df.dropna(inplace=True)  # Remove rows with unknown users/items\n",
        "test_df[['user', 'item']] = test_df[['user', 'item']].astype(int)  # Ensure they are integers\n",
        "\n",
        "# Extract user-item pairs from the test set\n",
        "X_test = test_df[['user', 'item']].values\n",
        "\n",
        "# Predict ratings using the trained model (assuming `M` and `Theta` are already defined from training)\n",
        "predictions = []\n",
        "print(\"Generating Predictions...\")\n",
        "\n",
        "# Loop through user-item pairs to make predictions\n",
        "for user, item in tqdm(X_test, desc=\"Predicting\", unit=\"pair\"):\n",
        "    if user < Theta.shape[0] and item < M.shape[0]:  # Ensure valid indices\n",
        "        pred = M[item].dot(Theta[user])  # Matrix multiplication for prediction\n",
        "    else:\n",
        "        pred = np.mean(y)  # Default to the mean rating if out of range\n",
        "\n",
        "    pred = np.clip(pred, 1, 5)  # Clip predictions between 1 and 5\n",
        "    predictions.append(pred)\n",
        "\n",
        "# Save predictions\n",
        "test_df['prediction'] = predictions\n",
        "test_df[['ID', 'prediction']].to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Predictions saved to predictions.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}