{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Algoritmo SVD**\n",
    "---\n",
    "El algoritmo SVD (Singular Value Decomposition) de recomendación es una técnica utilizada principalmente en sistemas de recomendación para predecir las valoraciones o preferencias de un usuario sobre ítems que no ha visto o calificado. SVD es un enfoque basado en factorización matricial, que descompone una matriz de interacciones (por ejemplo, una matriz de usuarios vs ítems con sus valoraciones) en tres matrices más pequeñas que capturan características latentes de los usuarios y los ítems.\n",
    "\n",
    "## **¿Cómo funciona el SVD en un sistema de recomendación?**\n",
    "\n",
    "Supón que tenemos una matriz \\( R \\) de **valoraciones** (ratings), donde las filas representan a los **usuarios** y las columnas representan a los **ítems**.\n",
    "\n",
    "Las celdas de la matriz contienen las valoraciones que los usuarios han dado a los ítems. Sin embargo, esta matriz es generalmente muy dispersa, ya que los usuarios solo valoran una pequeña fracción de los ítems disponibles.\n",
    "\n",
    "#### **Descomposición**:\n",
    "El algoritmo SVD descompone la matriz de valoraciones \\( R \\) en tres matrices:\n",
    "- **U (usuarios)**: Una matriz de características latentes de los usuarios (\\( m \\times k \\), donde \\( m \\) es el número de usuarios y \\( k \\) es el número de características latentes).\n",
    "- **Σ (singular values)**: Una matriz diagonal (\\( k \\times k \\)) con los valores singulares que representan la importancia de las características latentes.\n",
    "- **\\( V^T \\) (ítems)**: Una matriz de características latentes de los ítems (\\( k \\times n \\), donde \\( n \\) es el número de ítems).\n",
    "\n",
    "La descomposición completa es:\n",
    "\\[\n",
    "R \\approx U \\cdot \\Sigma \\cdot V^T\n",
    "\\]\n",
    "- \\( R \\) es la matriz original de valoraciones.\n",
    "- \\( U \\) es la matriz de usuarios con las características latentes de los usuarios.\n",
    "- \\( \\Sigma \\) es la matriz de los valores singulares que representa la importancia de cada característica latente.\n",
    "- \\( V^T \\) es la matriz transpuesta de ítems con las características latentes de los ítems.\n",
    "\n",
    "#### **Predicción**:\n",
    "La idea principal de SVD es **predecir las valoraciones faltantes** en la matriz \\( R \\), es decir, aquellas celdas en las que el usuario aún no ha dado una valoración. Para ello, una vez descompuesta la matriz \\( R \\), el modelo puede usar la multiplicación de las matrices \\( U \\cdot \\Sigma \\cdot V^T \\) para aproximar las valoraciones que el usuario podría dar a ítems no valorados.\n",
    "\n",
    "#### **Optimización**:\n",
    "En la práctica, los algoritmos de SVD como **SVD++** o **SVD de baja regularización** no simplemente calculan la descomposición, sino que también **optimizan los parámetros** mediante técnicas de aprendizaje automático como el **descenso por gradiente**. El objetivo es minimizar la diferencia entre las valoraciones predichas y las valoraciones reales (si están disponibles).\n",
    "\n",
    "#### **Regularización**:\n",
    "Dado que la matriz \\( R \\) puede ser muy dispersa y los modelos SVD pueden sobreajustar (overfitting) a los datos, se aplica **regularización** para evitar que el modelo se ajuste demasiado a las peculiaridades de los datos de entrenamiento. La regularización agrega un término al error de predicción que penaliza los valores grandes en las matrices \\( U \\), \\( \\Sigma \\) y \\( V \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reader Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-surprise --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import operator\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from scipy.special import digamma\n",
    "from math import exp\n",
    "\n",
    "df_train = pd.read_csv('train.csv', sep=',', index_col=False)\n",
    "df_test = pd.read_csv('test.csv', sep=',', index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25715</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25716</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>25851</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>25923</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>25924</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user   item  rating\n",
       "0     1  25715     7.0\n",
       "1     1  25716    10.0\n",
       "2     5  25851     9.0\n",
       "3     6  25923     5.0\n",
       "4     7  25924     6.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.dataset.DatasetAutoFolds'>\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0,10)) # rating scale range\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.trainset.Trainset'>\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "print(type(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Algoritmo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1fecbe35b20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7634623190271725"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exportacion de predicciones.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3891, 81714, 10.0),\n",
       " (49435, 77613, 8.0),\n",
       " (38654, 112871, 6.0),\n",
       " (69560, 55505, 10.0),\n",
       " (69799, 28638, 9.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row['user']\n",
    "    item = row['item']\n",
    "    \n",
    "    pred = algo.predict(user, item).est  # Predicción de rating\n",
    "    solution.append([row['ID'], pred])\n",
    "\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "\n",
    "solution_df.to_csv('predictions_svd.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta primera ejecución SVD devuelve un MAE: 1.263.\n",
    "\n",
    "En las siguientes celdas se aplica **GridSearch** de SVD para ajustar los hiperparametros. El siguiente primer GridSearch es general, sobre los parámetros más importantes de SVD: *[n_factors, n_epochs, lr_all, reg_all]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06}\n",
      "Predicciones guardadas en svd_gridsearch\\predictions_svd.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "output_dir = \"predictions/svd_gridsearch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Configurar el rango de ratings\n",
    "reader = Reader(rating_scale=(df_train[\"rating\"].min(), df_train[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_factors\": [50, 100, 150],     # Aumentar complejidad\n",
    "    \"n_epochs\": [20, 30, 50],        \n",
    "    \"lr_all\": [0.002, 0.005, 0.01],  # Ajuste de tasa de aprendizaje\n",
    "    \"reg_all\": [0.02, 0.04, 0.06],   # Regularización para evitar overfitting\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, n_jobs=-1, joblib_verbose=1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "### ENTRENO  EL MEJOR MODELO CON TODOS LOS DATOS\n",
    "best_svd = SVD(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_svd.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "\n",
    "output_file = os.path.join(output_dir, \"predictions_svd.csv\")\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la mejor solución anterior, con un MAE: 1.260 (Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06}), se vuelve a ejecutar un segundo GridSearch para refinar los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'n_factors': 40, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.05}\n",
      "Predicciones guardadas en predictions/svd_gridsearch\\predictions_svd_grid2.csv\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_factors\": [40, 50, 60],       \n",
    "    \"n_epochs\": [25, 30, 35],        \n",
    "    \"lr_all\": [0.004, 0.005, 0.006], \n",
    "    \"reg_all\": [0.05, 0.06, 0.07],  \n",
    "    \"biased\": True,\n",
    "    \n",
    "}\n",
    "\n",
    "algo = SVD()\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, n_jobs=-1, joblib_verbose=1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "best_svd = SVD(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_svd.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "output_file = os.path.join(output_dir, \"predictions_svd_grid2.csv\")\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se busca afinar la solución anterior con MAE: 1.262 (Mejores parámetros: {'n_factors': 40, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.05}) en base a nuevos parámetros: *[lr y reg]*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06, 'lr_bu': 0.005, 'lr_bi': 0.005, 'lr_pu': 0.002, 'lr_qi': 0.002, 'reg_bu': 0.02, 'reg_bi': 0.04}\n",
      "Predicciones guardadas en predictions/svd_gridsearch\\predictions_svd3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "output_dir = \"predictions/svd_gridsearch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Configurar el rango de ratings\n",
    "reader = Reader(rating_scale=(df_train[\"rating\"].min(), df_train[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_factors\": [50],  \n",
    "    \"n_epochs\": [30],   \n",
    "    \"lr_all\": [0.005],  \n",
    "    \"reg_all\": [0.06],  \n",
    "\n",
    "    \"lr_bu\": [0.002, 0.005],  \n",
    "    \"lr_bi\": [0.002, 0.005],  \n",
    "    \"lr_pu\": [0.002, 0.005],  \n",
    "    \"lr_qi\": [0.002, 0.005],  \n",
    "\n",
    "    \"reg_bu\": [0.02, 0.04],   \n",
    "    \"reg_bi\": [0.02, 0.04],   \n",
    "}\n",
    "\n",
    "algo = SVD()\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, n_jobs=-1, joblib_verbose=1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "best_svd = SVD(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_svd.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "output_file = os.path.join(output_dir, \"predictions_svd3.csv\")\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta nueva solución con un MAE de 1.250 (Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06, 'lr_bu': 0.005, 'lr_bi': 0.005, 'lr_pu': 0.002, 'lr_qi': 0.002, 'reg_bu': 0.02, 'reg_bi': 0.04}) se refina de nuevo por los parámetros *[lr y reg]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06, 'lr_bu': 0.01, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.002, 'reg_bu': 0.02, 'reg_bi': 0.02}\n",
      "Predicciones guardadas en predictions/svd_gridsearch\\predictions_svd4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "output_dir = \"predictions/svd_gridsearch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "reader = Reader(rating_scale=(df_train[\"rating\"].min(), df_train[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_factors\": [50],  \n",
    "    \"n_epochs\": [30],   \n",
    "    \"lr_all\": [0.005],  \n",
    "    \"reg_all\": [0.06],  \n",
    "\n",
    "    \"lr_bu\": [0.005, 0.01],  \n",
    "    \"lr_bi\": [0.005, 0.01],  \n",
    "    \"lr_pu\": [0.002, 0.001],  \n",
    "    \"lr_qi\": [0.002, 0.001],  \n",
    "\n",
    "    \"reg_bu\": [0.02, 0.04],   \n",
    "    \"reg_bi\": [0.02, 0.04],   \n",
    "}\n",
    "\n",
    "algo = SVD()\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, n_jobs=-1, joblib_verbose=1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "best_svd = SVD(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_svd.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "output_file = os.path.join(output_dir, \"predictions_svd4.csv\")\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución anterior con un MAE DE 1.242 (Mejores parámetros: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.06, 'lr_bu': 0.01, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.002, 'reg_bu': 0.02, 'reg_bi': 0.02}) se termina de ajustar con el ajuste de Epochs y n_factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'n_factors': 45, 'n_epochs': 25, 'lr_all': 0.005, 'reg_all': 0.06, 'lr_bu': 0.015, 'lr_bi': 0.005, 'lr_pu': 0.001, 'lr_qi': 0.002, 'reg_bu': 0.02, 'reg_bi': 0.02}\n",
      "Predicciones guardadas en predictions/svd_gridsearch\\predictions_svd5.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "output_dir = \"predictions/svd_gridsearch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "reader = Reader(rating_scale=(df_train[\"rating\"].min(), df_train[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_factors\": [45, 50, 55],  \n",
    "    \"n_epochs\": [25, 30, 35],   \n",
    "    \"lr_all\": [0.005],          \n",
    "    \"reg_all\": [0.06],         \n",
    "\n",
    "    \"lr_bu\": [0.01, 0.015],      \n",
    "    \"lr_bi\": [0.005],           \n",
    "    \"lr_pu\": [0.001],          \n",
    "    \"lr_qi\": [0.002],           \n",
    "\n",
    "    \"reg_bu\": [0.02],           \n",
    "    \"reg_bi\": [0.02],           \n",
    "}\n",
    "\n",
    "algo = SVD()\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=4, n_jobs=-1, joblib_verbose=1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "best_svd = SVD(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_svd.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "output_file = os.path.join(output_dir, \"predictions_svd5.csv\")\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La configuración de parámetros ideal es \n",
    "`{   'n_factors': 45, \n",
    "    'n_epochs': 25, \n",
    "    'lr_all': 0.005, \n",
    "    'reg_all': 0.06, \n",
    "    'lr_bu': 0.015, \n",
    "    'lr_bi': 0.005, \n",
    "    'lr_pu': 0.001, \n",
    "    'lr_qi': 0.002, \n",
    "    'reg_bu': 0.02, \n",
    "    'reg_bi': 0.02   }.` "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4. BNMF.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
