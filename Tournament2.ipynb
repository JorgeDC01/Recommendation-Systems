{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d5891b",
   "metadata": {},
   "source": [
    "# **SISTEMAS DE RECOMENDACIÓN**\n",
    "\n",
    "## **Filtrado Basado en Contenido**\n",
    "\n",
    "\n",
    "Miembros del Grupo:\n",
    "- Paula Arias Fernández\n",
    "- Jorge del Castillo Gómez\n",
    "- Anny Álvarez Nogales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BORRAR ESTE COMENTARIO CUANDO LO LEÁIS\n",
    "#Sigo la estructura de la presentación \n",
    "# (dejo los huequitos antes de mi código pero si queréis cambiar \n",
    "# el orden de algo o moverlo sin problema que no sabia como ponerlo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f07809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee12784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23312fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d0650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7c797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a39f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa142c74",
   "metadata": {},
   "source": [
    "# **Pruebas Datos Textuales** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97de994",
   "metadata": {},
   "source": [
    "## Word2Vec Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATOS\n",
    "train_reviews=pd.read_csv('train_reviews.csv', sep=',')\n",
    "test_reviews = pd.read_csv('test_reviews.csv')\n",
    "negocios_df=pd.read_csv('negocios.csv')\n",
    "\n",
    "df = train_reviews.merge(negocios_df, on='business_id',how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a526937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESS DATA \n",
    "\n",
    "df['text'] = df['text'].astype(str) + \" \" + df['categories'].astype(str)\n",
    "\n",
    "def preprocess_text_parallel(text):\n",
    "    return re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "\n",
    "train_reviews['tokens'] = Parallel(n_jobs=-1)(delayed(preprocess_text_parallel)(text) for text in df['text'])\n",
    "test_reviews['tokens'] = Parallel(n_jobs=-1)(delayed(preprocess_text_parallel)(text) for text in test_reviews['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT MODEL WORD2VEC\n",
    "#se entrena una vez y se guarda el modelo\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(\n",
    "    sentences=train_reviews['tokens'],\n",
    "    vector_size=50,  \n",
    "    window=5,\n",
    "    min_count=5,  \n",
    "    workers=4,  \n",
    "    epochs=7 \n",
    ")\n",
    "\n",
    "\n",
    "#model.save(\"word2vec_model.model\")\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d112e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY TEXT EMBEDDING MODEL\n",
    "def get_review_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return [0] * model.vector_size  \n",
    "    return sum(vectors) / len(vectors)\n",
    "\n",
    "train_reviews['vector'] = train_reviews['tokens'].apply(lambda x: get_review_vector(x, model))\n",
    "\n",
    "X_train = list(train_reviews['vector'])\n",
    "y_train = train_reviews['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFIER LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=2500,C= 14.867708330182724,solver='newton-cg',penalty='l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "test_reviews['vector'] = test_reviews['tokens'].apply(lambda x: get_review_vector(x, model))\n",
    "\n",
    "X_test = list(test_reviews['vector'])\n",
    "predicted_stars = classifier.predict(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'review_id': test_reviews['review_id'],\n",
    "    'stars': predicted_stars\n",
    "})\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFIER RANDOMFOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "test_reviews['vector'] = test_reviews['tokens'].apply(lambda x: get_review_vector(x, model))\n",
    "\n",
    "X_test = list(test_reviews['vector'])\n",
    "predicted_stars = classifier.predict(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'review_id': test_reviews['review_id'],\n",
    "    'stars': predicted_stars\n",
    "})\n",
    "\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a62f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST CLASSIFIER\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "y_train_adj = y_train - 1\n",
    "\n",
    "classifier = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "classifier.fit(X_train, y_train_adj)\n",
    "\n",
    "X_test = list(test_reviews['vector'])\n",
    "predicted_stars = classifier.predict(X_test) + 1  \n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'review_id': test_reviews['review_id'],\n",
    "    'stars': predicted_stars\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69630a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTUNA WITH LOGISTIC REGRESSION\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Optimización para el mejor modelo de regresión logística\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-5, 100)  \n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'lbfgs', 'newton-cg', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 1000, 5000, step=500)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2'])\n",
    "\n",
    "    classifier = LogisticRegression(C=C, solver=solver, max_iter=max_iter, penalty=penalty)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    predicted_stars = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predicted_stars)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maximize accuracy\n",
    "study = optuna.create_study(direction='maximize')  \n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "best_classifier = LogisticRegression(**best_params)\n",
    "best_classifier.fit(X_train, y_train)\n",
    "\n",
    "#evaluation\n",
    "final_predictions = best_classifier.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Final Accuracy: {final_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185d9cf",
   "metadata": {},
   "source": [
    "## Fast Text Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT MODEL FAST TEXT\n",
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "fasttext_model = FastText(sentences=train_reviews['tokens'], vector_size=50, window=5, min_count=5, epochs=10)\n",
    "fasttext_model.save(\"fasttext_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return [0] * model.vector_size\n",
    "    \n",
    "    return sum(vectors) / len(vectors)\n",
    "\n",
    "train_reviews['vector'] = train_reviews['tokens'].apply(lambda x: get_review_vector(x, fasttext_model))\n",
    "\n",
    "X_train = list(train_reviews['vector'])\n",
    "y_train = train_reviews['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST CLASSIFIER\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "y_train_adj = y_train - 1\n",
    "\n",
    "classifier = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "classifier.fit(X_train, y_train_adj)\n",
    "\n",
    "X_test = list(test_reviews['vector'])\n",
    "predicted_stars = classifier.predict(X_test) + 1  \n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'review_id': test_reviews['review_id'],\n",
    "    'stars': predicted_stars\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d08e13",
   "metadata": {},
   "source": [
    "# **Pruebas Datos No Textuales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99164546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES SELECTION\n",
    "usuarios=pd.read_csv('usuarios.csv', sep=',')\n",
    "\n",
    "df = df.merge(usuarios, on='user_id',how='inner')\n",
    "\n",
    "df2=df.drop(['review_id',\t'user_id'\t,'business_id','text', 'date', 'name_x','address','city','state','attributes','categories','name_y','elite','friends','hours','yelping_since','postal_code'],axis=1)\n",
    "df2.rename(columns={'stars_x':'stars','name_y':'user_name','useful_x':'useful','funny_x':'funny','cool_x':'cool'}, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO TEXTUAL DATA NORMALIZATION\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df2=df2[['funny','stars','cool','useful']]\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "y_train = df2['stars'].round().astype(int)  \n",
    "X_train = df2.drop(columns=['stars'])  \n",
    "\n",
    "\n",
    "# Normalización\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Entrenamiento\n",
    "classifier = LogisticRegression(max_iter=3000)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER\n",
    "\n",
    "#X_test_scaled = scaler.transform(test_reviews)\n",
    "common_cols = list(set(X_train.columns) & set(test_reviews.columns))\n",
    "X_test = test_reviews[common_cols]\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "X_test_scaled\n",
    "predicted_stars = classifier.predict(X_test_scaled)\n",
    "predicted_stars\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'review_id': test_reviews['review_id'],\n",
    "    'stars': predicted_stars\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
