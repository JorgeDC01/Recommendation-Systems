{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Algoritmo NMF**\n",
    "---\n",
    "\n",
    "### **¿Cómo funciona el NMF en un sistema de recomendación?**\n",
    "\n",
    "#### **Representación de los datos:**\n",
    "Supón que tenemos una matriz \\( R \\) de **valoraciones** (ratings), donde las filas representan a los **usuarios** y las columnas representan a los **ítems**.\n",
    "\n",
    "Las celdas de la matriz contienen las valoraciones que los usuarios han dado a los ítems. Esta matriz es generalmente **dispersa**, ya que los usuarios solo valoran una pequeña fracción de los ítems disponibles.\n",
    "\n",
    "#### **Descomposición:**\n",
    "El algoritmo NMF descompone la matriz de valoraciones \\( R \\) en dos matrices de características no negativas:\n",
    "- **W (usuarios)**: Una matriz de características latentes de los usuarios (\\( m \\times k \\), donde \\( m \\) es el número de usuarios y \\( k \\) es el número de características latentes).\n",
    "- **H (ítems)**: Una matriz de características latentes de los ítems (\\( k \\times n \\), donde \\( n \\) es el número de ítems).\n",
    "\n",
    "La descomposición completa es:\n",
    "\\[\n",
    "R \\approx W \\cdot H\n",
    "\\]\n",
    "- \\( R \\) es la matriz original de valoraciones.\n",
    "- \\( W \\) es la matriz de usuarios con las características latentes de los usuarios.\n",
    "- \\( H \\) es la matriz de ítems con las características latentes de los ítems.\n",
    "\n",
    "#### **Predicción:**\n",
    "La idea principal de NMF es **predecir las valoraciones faltantes** en la matriz \\( R \\), es decir, aquellas celdas en las que el usuario aún no ha dado una valoración. Para ello, una vez descompuesta la matriz \\( R \\), el modelo puede usar la multiplicación de las matrices \\( W \\cdot H \\) para aproximar las valoraciones que el usuario podría dar a ítems no valorados.\n",
    "\n",
    "#### **Optimización:**\n",
    "NMF realiza la descomposición de la matriz \\( R \\) de manera que las matrices \\( W \\) y \\( H \\) contienen **valores no negativos**. Esto hace que el modelo sea especialmente adecuado para tareas de recomendación, ya que las valoraciones y las características latentes no pueden ser negativas. Para obtener una buena descomposición, se optimizan los valores de \\( W \\) y \\( H \\) mediante técnicas de **optimización iterativa**, como el descenso por gradiente o la actualización de las reglas de multiplicación.\n",
    "\n",
    "#### **Regularización:**\n",
    "Al igual que en otros métodos de factorización de matrices, se aplica **regularización** en NMF para evitar el sobreajuste (overfitting) a los datos de entrenamiento. La regularización penaliza la complejidad del modelo, evitando que las matrices \\( W \\) y \\( H \\) contengan valores demasiado grandes. Esto mejora la capacidad de generalización del modelo y previene el sobreajuste a las peculiaridades de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reader Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pXAbayjuSqc"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import random\n",
    "from scipy.special import digamma\n",
    "from math import exp\n",
    "import os\n",
    "import random\n",
    "import operator\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import sys\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-surprise --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.csv', sep=',', index_col=False)\n",
    "df_test = pd.read_csv('test.csv', sep=',', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25715</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25716</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>25851</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>25923</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>25924</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user   item  rating\n",
       "0     1  25715     7.0\n",
       "1     1  25716    10.0\n",
       "2     5  25851     9.0\n",
       "3     6  25923     5.0\n",
       "4     7  25924     6.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.dataset.DatasetAutoFolds'>\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0,10)) # rating scale range\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.trainset.Trainset'>\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "print(type(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Algoritmo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "MAE:  1.7760\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, NMF\n",
    "\n",
    "algo = NMF(n_factors=15, n_epochs=50, biased=False, reg_pu=0.06, reg_qi=0.06, random_state=42, verbose=True)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "solution = []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row['user']\n",
    "    item = row['item']\n",
    "    \n",
    "    pred = algo.predict(user, item).est  # Predicción de rating\n",
    "    solution.append([row['ID'], pred])\n",
    "\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "\n",
    "solution_df.to_csv('predictions_nmf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 50\n",
      "Processing epoch 51\n",
      "Processing epoch 52\n",
      "Processing epoch 53\n",
      "Processing epoch 54\n",
      "Processing epoch 55\n",
      "Processing epoch 56\n",
      "Processing epoch 57\n",
      "Processing epoch 58\n",
      "Processing epoch 59\n",
      "Processing epoch 60\n",
      "Processing epoch 61\n",
      "Processing epoch 62\n",
      "Processing epoch 63\n",
      "Processing epoch 64\n",
      "Processing epoch 65\n",
      "Processing epoch 66\n",
      "Processing epoch 67\n",
      "Processing epoch 68\n",
      "Processing epoch 69\n",
      "Processing epoch 70\n",
      "Processing epoch 71\n",
      "Processing epoch 72\n",
      "Processing epoch 73\n",
      "Processing epoch 74\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, NMF\n",
    "\n",
    "algo = NMF(n_factors=40, n_epochs=75, biased=False, reg_pu=0.06, reg_qi=0.06, random_state=42, verbose=True)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# accuracy.mae(predictions)\n",
    "\n",
    "solution = []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row['user']\n",
    "    item = row['item']\n",
    "    \n",
    "    pred = algo.predict(user, item).est  # Predicción de rating\n",
    "    solution.append([row['ID'], pred])\n",
    "\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "\n",
    "solution_df.to_csv('predictions_nmf_k40_e75.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, NMF\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "output_dir = \"nmf_gridsearch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")  \n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "reader = Reader(rating_scale=(df_train[\"rating\"].min(), df_train[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_factors\": [10, 15, 20],\n",
    "    \"n_epochs\": [30, 50, 70],\n",
    "    \"reg_pu\": [0.04, 0.06, 0.08],\n",
    "    \"reg_qi\": [0.04, 0.06, 0.08],\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(NMF, param_grid, measures=[\"mae\"], cv=3, n_jobs=-1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "best_params = grid_search.best_params[\"mae\"]\n",
    "print(f\"Mejores parámetros: {best_params}\")\n",
    "\n",
    "# Entrenar el mejor modelo con todos los datos\n",
    "best_nmf = NMF(**best_params, random_state=42)\n",
    "trainset = data.build_full_trainset()\n",
    "best_nmf.fit(trainset)\n",
    "\n",
    "solution = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row[\"user\"]\n",
    "    item = row[\"item\"]\n",
    "    pred = best_nmf.predict(user, item).est\n",
    "    solution.append([row[\"ID\"], pred])\n",
    "\n",
    "solution_df = pd.DataFrame(solution, columns=[\"ID\", \"rating\"])\n",
    "output_file = os.path.join(output_dir, \"predictions_nmf.csv\")\n",
    "solution_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Predicciones guardadas en {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4. BNMF.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
